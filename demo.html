<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Face → MorphTargets (minimal)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    html,body{margin:0;height:100%;background:#111;color:#ddd;font:14px system-ui}
    /* App layout: left = view, right = sidebar (controls top, camera bottom) */
    .app{display:grid;grid-template-columns:1fr 360px;grid-template-rows:100vh}
    .view{position:relative;overflow:hidden}
    .sidebar{display:grid;grid-template-rows:1fr auto;gap:8px;padding:8px}
    #ui{background:#1b1b1b;border:1px solid #333;padding:10px;border-radius:8px}
    #camWrap{position:relative;border:1px solid #333;border-radius:6px;overflow:hidden}
    #video{display:block;width:100%;height:auto;object-fit:cover;opacity:.9}
    #overlay{position:absolute;inset:0;pointer-events:none}
    #morphKeys{max-width:100%;max-height:110px;overflow:auto;font-family:monospace;background:#0f0f0f;padding:6px;border:1px solid #222;border-radius:6px}
    canvas#three{display:block;width:100%;height:100%}
    .err{color:#e37b7b}
  </style>
</head>
<body>
  <div class="app">
    <!-- LEFT: 3D view -->
    <div class="view">
      <canvas id="three"></canvas>
    </div>

    <!-- RIGHT: controls (top) + camera (bottom) -->
    <div class="sidebar">
      <div id="ui">
        <div><b>Face-driven rig</b></div>
        <label>Upload GLB/GLTF (with morph targets)</label>
        <input type="file" id="file" accept=".glb,.gltf" />
        <label>Detected morph target keys</label>
        <div id="morphKeys"></div>
        <label>Mapping</label>
        <div style="display:grid;grid-template-columns:120px 1fr;gap:4px;align-items:center">
          <div>jawOpen →</div><input id="mapJaw" placeholder="JawOpen, mouthOpen">
          <div>eyeBlinkLeft →</div><input id="mapBlinkL" placeholder="eyeBlinkLeft, Blink_L">
          <div>eyeBlinkRight →</div><input id="mapBlinkR" placeholder="eyeBlinkRight, Blink_R">
          <div>mouthSmile →</div><input id="mapSmile" placeholder="mouthSmile, Smile">
        </div>
        <div id="status">Waiting for model…</div>
      </div>

      <div id="camWrap">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
      </div>
    </div>
  </div>

  <!-- Three.js scene (single) -->
  <script type="module">
    import * as THREE from "https://cdn.jsdelivr.net/npm/three@0.160.0/+esm";
    import { GLTFLoader } from "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/loaders/GLTFLoader.js/+esm";
    import { OrbitControls } from "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/controls/OrbitControls.js/+esm";

    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const canvas = document.getElementById('three');
    const statusEl = document.getElementById('status');
    const morphKeysEl = document.getElementById('morphKeys');
    const mapInputs = {
      jawOpen: document.getElementById('mapJaw'),
      eyeBlinkLeft: document.getElementById('mapBlinkL'),
      eyeBlinkRight: document.getElementById('mapBlinkR'),
      mouthSmile: document.getElementById('mapSmile'),
    };

    // Scene
    const renderer = new THREE.WebGLRenderer({ canvas, antialias:true, alpha:true });
    renderer.setPixelRatio(Math.min(devicePixelRatio, 2));
    const scene = new THREE.Scene(); scene.background = new THREE.Color(0x111111);
    const camera = new THREE.PerspectiveCamera(35, 1, 0.01, 100); camera.position.set(0,1.2,2.2);
    const hemi = new THREE.HemisphereLight(0xffffff,0x222233,1.1); scene.add(hemi);
    const dir  = new THREE.DirectionalLight(0xffffff,1.1); dir.position.set(2,3,2); scene.add(dir);
    const grid = new THREE.GridHelper(6,12,0x333333,0x222222); grid.position.y=-1; scene.add(grid);

    // Orbit controls and framing
    const controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.dampingFactor = 0.08;
    controls.minDistance = 0.5;
    controls.maxDistance = 10;
    controls.enablePan = true;
    controls.target.set(0, 1, 0);

    function frameObject(obj) {
      const box = new THREE.Box3().setFromObject(obj);
      const sizeV = box.getSize(new THREE.Vector3());
      const size = Math.max(sizeV.x, sizeV.y, sizeV.z);
      const center = box.getCenter(new THREE.Vector3());

      const fitHeight = size / (2 * Math.tan(THREE.MathUtils.degToRad(camera.fov * 0.5)));
      const fitWidth  = fitHeight / camera.aspect;
      const dist = 1.2 * Math.max(fitHeight, fitWidth);

      camera.near = Math.max(0.01, size / 100);
      camera.far  = Math.max(100, size * 10);
      camera.position.copy(center).add(new THREE.Vector3(0, size * 0.15, dist));
      camera.updateProjectionMatrix();

      controls.target.copy(center);
      controls.update();
    }

    function resize(){
      const view = canvas.parentElement.getBoundingClientRect();
      renderer.setSize(view.width, view.height, false);
      camera.aspect = view.width / view.height;
      camera.updateProjectionMatrix();

      // Match overlay to video’s rendered size
      const vr = document.getElementById('video').getBoundingClientRect();
      overlay.width  = Math.max(1, Math.floor(vr.width));
      overlay.height = Math.max(1, Math.floor(vr.height));
    }
    addEventListener('resize', resize);
    new ResizeObserver(resize).observe(document.body);
    resize();

    (function loop(){
      requestAnimationFrame(loop);
      controls.update();
      renderer.render(scene, camera);
    })();

    // Support ALL morph meshes
    let morphRefs = []; // Array of {dict, influences}
    const gltfLoader = new GLTFLoader();

    function collectMorphMeshes(root){
      const out=[]; root.traverse(o=>{
        if(o.isMesh && o.morphTargetDictionary && o.morphTargetInfluences){
          out.push({ dict:o.morphTargetDictionary, inf:o.morphTargetInfluences });
        }
      });
      return out;
    }
    function unionMorphKeys(refs){
      const s=new Set();
      refs.forEach(r=>Object.keys(r.dict).forEach(k=>s.add(k)));
      return Array.from(s).sort();
    }
    function tryAutoMap(keys){
      const L = keys.map(k=>k.toLowerCase());
      const pick = c => c.find(n=>L.includes(n.toLowerCase())) || '';
      mapInputs.jawOpen.value     ||= pick(['JawOpen','jawOpen','mouthOpen','MouthOpen']);
      mapInputs.eyeBlinkLeft.value||= pick(['eyeBlinkLeft','Blink_L','blinkLeft','EyeBlinkLeft']);
      mapInputs.eyeBlinkRight.value||=pick(['eyeBlinkRight','Blink_R','blinkRight','EyeBlinkRight']);
      mapInputs.mouthSmile.value  ||= pick(['mouthSmile','Smile','smile','MouthSmile','SmileBoth']);
    }

    document.getElementById('file').addEventListener('change', async (e)=>{
      const file = e.target.files?.[0]; if(!file) return;
      statusEl.textContent = 'Loading model…';
      const url = URL.createObjectURL(file);
      try{
        const gltf = await gltfLoader.loadAsync(url);
        gltf.scene.position.set(0,-1,0);
        scene.add(gltf.scene);
        frameObject(gltf.scene);

        morphRefs = collectMorphMeshes(gltf.scene);

        // Resolve head node and expose to window for the non-module script
        let headNode = null;
        (function resolveHeadBone(root){
          const names = [/head/i, /Head_JNT/i, /DEF-Head/i, /mixamorigHead/i];
          root.traverse(o=>{
            if(!headNode && o.isBone && names.some(rx=>rx.test(o.name))) headNode = o;
          });
          if(!headNode) headNode = root;
        })(gltf.scene);
        window.headNode = headNode;
        // neutralize baked pose to reduce surprises
        if (headNode && headNode.quaternion) headNode.quaternion.set(0,0,0,1);


        if(morphRefs.length===0){ statusEl.innerHTML = '<span class="err">No morph targets found.</span>'; return; }

        const keys = unionMorphKeys(morphRefs);
        morphKeysEl.textContent = keys.join(', ');
        tryAutoMap(keys);

        statusEl.textContent = 'Model ready. Starting webcam + tracking…';
      }catch(err){ console.error(err); statusEl.innerHTML = '<span class="err">Model load failed.</span>'; }
      finally{ URL.revokeObjectURL(url); }
    });

    // Expose to next script
    window.__rigShared__ = {
      get morphRefs(){return morphRefs;},
      mapInputs
    };
  </script>

  <!-- MediaPipe FaceMesh (UMD globals) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/face_mesh.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>

  <script>
    const statusEl2 = document.getElementById('status');
    const video2 = document.getElementById('video');
    const overlay2 = document.getElementById('overlay');
    const ctx = overlay2.getContext('2d');

    const clamp01 = v => Math.max(0, Math.min(1, v));
    const IDX = { LIP_TOP_IN:13, LIP_BOT_IN:14, MOUTH_L:61, MOUTH_R:291, EYE_L_TOP:159, EYE_L_BOT:145, EYE_R_TOP:386, EYE_R_BOT:374, FACE_L:33, FACE_R:263 };
    const ema = a=>{ let y=0,init=false; return v=>{ y = init ? (a*v+(1-a)*y) : (init=true,v); return y; }; };
    const smooth = { jaw:ema(0.5), blinkL:ema(0.5), blinkR:ema(0.5), smile:ema(0.5) };
    const dist = (a,b)=>Math.hypot(a.x-b.x,a.y-b.y);

    // Clean single definition
    // replace the whole featuresFromLandmarks() definition
function featuresFromLandmarks(L){
  const dist = (a,b)=>Math.hypot(a.x-b.x,a.y-b.y,a.z-b.z);
  const clamp01 = v => Math.max(0, Math.min(1, v));

  // mouth features (unchanged logic constants kept tight)
  const faceW = Math.max(1e-6, dist(L[33], L[263]));
  let jawOpen = (dist(L[13], L[14]) / faceW - 0.02) * 6.0;
  let smile   = (dist(L[61], L[291]) / faceW - 0.35) * 3.0;
  let funnel  = ((dist(L[0], L[17]) / faceW) - 0.28) * -6.0;
  let puff    = ((dist(L[308],L[78]) / faceW) - 0.38) * -4.0;

  let eyeOpenL = dist(L[159], L[145]) / faceW;
  let eyeOpenR = dist(L[386], L[374]) / faceW;
  let blinkL = (0.06 - eyeOpenL) * 20.0;
  let blinkR = (0.06 - eyeOpenR) * 20.0;

  // --- robust head pose ---
  // pick stable anchors: left/right temples and forehead-to-chin
  const vL = L[33], vR = L[263], vChin = L[152], vFore = L[10];

  // build raw axes
  const Xr = {x:(vR.x-vL.x), y:(vR.y-vL.y), z:(vR.z-vL.z)};           // right
  const Yr = {x:(vFore.x-vChin.x), y:(vFore.y-vChin.y), z:(vFore.z-vChin.z)}; // up-ish
  const norm = v=>{const m=Math.hypot(v.x,v.y,v.z)||1; return {x:v.x/m,y:v.y/m,z:v.z/m};};
  const cross = (a,b)=>({x:a.y*b.z-a.z*b.y, y:a.z*b.x-a.x*b.z, z:a.x*b.y-a.y*b.x});

  // Gram-Schmidt: orthonormal basis to kill drift
  let X = norm(Xr);
  let Y = norm(Yr);
  let Z = norm(cross(Y, X));
  Y = norm(cross(Z, X));

  // rotation matrix (columns are basis vectors in camera space)
  const m00=X.x, m01=Y.x, m02=Z.x;
  const m10=X.y, m11=Y.y, m12=Z.y;
  const m20=X.z, m21=Y.z, m22=Z.z;

  // matrix -> quaternion (right-handed)
  let qw, qx, qy, qz;
  const t = m00 + m11 + m22;
  if (t > 0) {
    const s = Math.sqrt(t + 1.0) * 2; // s = 4*qw
    qw = 0.25 * s;
    qx = (m21 - m12) / s;
    qy = (m02 - m20) / s;
    qz = (m10 - m01) / s;
  } else if (m00 > m11 && m00 > m22) {
    const s = Math.sqrt(1.0 + m00 - m11 - m22) * 2;
    qw = (m21 - m12) / s;
    qx = 0.25 * s;
    qy = (m01 + m10) / s;
    qz = (m02 + m20) / s;
  } else if (m11 > m22) {
    const s = Math.sqrt(1.0 + m11 - m00 - m22) * 2;
    qw = (m02 - m20) / s;
    qx = (m01 + m10) / s;
    qy = 0.25 * s;
    qz = (m12 + m21) / s;
  } else {
    const s = Math.sqrt(1.0 + m22 - m00 - m11) * 2;
    qw = (m10 - m01) / s;
    qx = (m02 + m20) / s;
    qy = (m12 + m21) / s;
    qz = 0.25 * s;
  }

  // output with smoothed activations
  return {
    jawOpen:       smooth.jaw(clamp01(jawOpen)),
    mouthSmile:    smooth.smile(clamp01(smile)),
    mouthFunnel:   clamp01(ema(0.5)(funnel)),
    mouthPuff:     clamp01(ema(0.5)(puff)),
    eyeBlinkLeft:  clamp01(smooth.blinkL(blinkL)),
    eyeBlinkRight: clamp01(smooth.blinkR(blinkR)),
    headQuat: {x:qx,y:qy,z:qz,w:qw}
  };
}

// persistent quaternion & slerp
let _qCurrent = {x:0,y:0,z:0,w:1};
function _qNormalize(q){
  const m = Math.hypot(q.x,q.y,q.z,q.w)||1; return {x:q.x/m,y:q.y/m,z:q.z/m,w:q.w/m};
}
function _qDot(a,b){return a.x*b.x+a.y*b.y+a.z*b.z+a.w*b.w;}
function _qSlerp(a,b,t){
  let cos = _qDot(a,b);
  // take shortest path
  if (cos < 0) { b = {x:-b.x,y:-b.y,z:-b.z,w:-b.w}; cos = -cos; }
  if (cos > 0.9995) { // nearly linear
    const x=a.x+(b.x-a.x)*t, y=a.y+(b.y-a.y)*t, z=a.z+(b.z-a.z)*t, w=a.w+(b.w-a.w)*t;
    return _qNormalize({x,y,z,w});
  }
  const th = Math.acos(cos);
  const s = Math.sin(th);
  const w1 = Math.sin((1-t)*th)/s, w2 = Math.sin(t*th)/s;
  return {x:a.x*w1+b.x*w2, y:a.y*w1+b.y*w2, z:a.z*w1+b.z*w2, w:a.w*w2+b.w*w2};
}



    // Apply to ALL morph meshes and mouth shapes. Rotate head without THREE import.
    function applyToMorphs(feat){
      const shared = window.__rigShared__; if(!shared?.morphRefs?.length) return;
      const names = {
        jawOpen: shared.mapInputs.jawOpen.value.trim(),
        eyeBlinkLeft: shared.mapInputs.eyeBlinkLeft.value.trim(),
        eyeBlinkRight: shared.mapInputs.eyeBlinkRight.value.trim(),
        mouthSmile: shared.mapInputs.mouthSmile.value.trim(),
      };

      // Head pose → quaternion slerp to avoid flips
if (window.headNode && feat.headQuat) {
  const hn = window.headNode;
  const t = 0.25; // smoothing factor
  const target = _qNormalize(feat.headQuat);
  _qCurrent = _qSlerp(_qCurrent, target, t);
  // apply to THREE.Euler via setFromQuaternion if available
  if (hn.quaternion && hn.quaternion.set) {
    hn.quaternion.set(_qCurrent.x, _qCurrent.y, _qCurrent.z, _qCurrent.w);
  } else {
    // fallback: approximate by deriving eulers
    const q = _qCurrent, x=q.x,y=q.y,z=q.z,w=q.w;
    // yxz order matches typical head rigs
    const test = 2*(w*y - z*x);
    const yaw  = Math.asin(Math.max(-1, Math.min(1, test))); // Y
    const pitch= Math.atan2(2*(w*x + y*z), 1 - 2*(x*x + y*y)); // X
    const roll = Math.atan2(2*(w*z + x*y), 1 - 2*(y*y + z*z)); // Z
    hn.rotation.set(pitch, yaw, roll, 'YXZ');
  }
}


      for(const ref of shared.morphRefs){
        // Explicit mappings
        for(const [k,v] of Object.entries(names)){
          const name = names[k]; if(name && ref.dict[name]!==undefined){
            ref.inf[ref.dict[name]] = Math.max(0, Math.min(1, feat[k] ?? 0));
          }
        }
        // Heuristic drive for mouth-related shapes
        const keys = Object.keys(ref.dict);
        for(const key of keys){
          const lk = key.toLowerCase();
          if(/jaw/.test(lk))                 ref.inf[ref.dict[key]] = feat.jawOpen ?? 0;
          else if(/mouth.*open/.test(lk))    ref.inf[ref.dict[key]] = feat.jawOpen ?? 0;
          else if(/smile|wide/.test(lk))     ref.inf[ref.dict[key]] = feat.mouthSmile ?? 0;
          else if(/funnel|pucker|kiss/.test(lk)) ref.inf[ref.dict[key]] = feat.mouthFunnel ?? 0;
          else if(/puff|inflate|cheek/.test(lk)) ref.inf[ref.dict[key]] = feat.mouthPuff ?? 0;
          else if(/press|close/.test(lk))    ref.inf[ref.dict[key]] = (1 - (feat.jawOpen ?? 0));
          else if(/lip.*upper.*up/.test(lk)) ref.inf[ref.dict[key]] = (feat.mouthSmile ?? 0) * 0.6;
          else if(/lip.*lower.*down/.test(lk)) ref.inf[ref.dict[key]] = (feat.jawOpen ?? 0) * 0.7;
        }
      }
    }

    function drawLandmarks(lm){
      const w = overlay2.width, h = overlay2.height;
      if(!w||!h) return;
      ctx.clearRect(0,0,w,h);
      ctx.lineWidth = Math.max(1, w/320);
      ctx.strokeStyle = '#00ff88';
      ctx.fillStyle = '#00ff88';

      // Points
      ctx.beginPath();
      for(const p of lm){
        const x = p.x * w;
        const y = p.y * h;
        ctx.moveTo(x+1, y);
        ctx.arc(x, y, Math.max(1, w/300), 0, Math.PI*2);
      }
      ctx.fill();

      // Simple mouth outline
      const mouthIdx = [61,146,91,181,84,17,314,405,321,375,291];
      ctx.beginPath();
      mouthIdx.forEach((i,ix)=>{
        const p = lm[i]; const x=p.x*w, y=p.y*h;
        if(ix===0) ctx.moveTo(x,y); else ctx.lineTo(x,y);
      });
      ctx.closePath(); ctx.stroke();
    }

    async function boot(){
      const stream = await navigator.mediaDevices.getUserMedia({ video:{ facingMode:'user', width:640, height:480 }, audio:false });
      video2.srcObject = stream; await video2.play();

      // Match overlay to displayed size
      const syncOverlay = ()=> {
        const vr = video2.getBoundingClientRect();
        overlay2.width  = Math.max(1, Math.floor(vr.width));
        overlay2.height = Math.max(1, Math.floor(vr.height));
      };
      video2.addEventListener('loadedmetadata', syncOverlay);
      new ResizeObserver(syncOverlay).observe(document.getElementById('camWrap'));

      const faceMesh = new FaceMesh({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/${f}` });
      faceMesh.setOptions({ maxNumFaces:1, refineLandmarks:true, minDetectionConfidence:0.5, minTrackingConfidence:0.5 });
      faceMesh.onResults(res => {
        const lm = res.multiFaceLandmarks && res.multiFaceLandmarks[0]; if(!lm) return;
        drawLandmarks(lm);
        applyToMorphs(featuresFromLandmarks(lm));
      });

      const cam = new Camera(video2, { onFrame: async()=>{ await faceMesh.send({ image: video2 }); }, width:640, height:480 });
      cam.start();
      statusEl2.textContent = 'Tracking running. Move your face.';
    }
    document.addEventListener('DOMContentLoaded', boot);
  </script>
</body>
</html>
