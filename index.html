<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>mirror face</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    html,body{margin:0;height:100%;background:#111;color:#ddd;font:14px system-ui}
    .app{display:grid;grid-template-columns:1fr 360px;grid-template-rows:100vh}
    .view{position:relative;overflow:hidden}
    .sidebar{display:grid;grid-template-rows:1fr auto;gap:8px;padding:8px;overflow-y:auto}
    #ui{background:#1b1b1b;border:1px solid #333;padding:10px;border-radius:8px}
    #camWrap{position:relative;border:1px solid #333;border-radius:6px;overflow:hidden}
    #video{display:block;width:100%;height:auto;object-fit:cover;opacity:.9}
    #overlay{position:absolute;inset:0;pointer-events:none}
    #morphKeys{max-width:100%;max-height:110px;overflow:auto;font-family:monospace;background:#0f0f0f;padding:6px;border:1px solid #222;border-radius:6px;font-size:11px}
    canvas#three{display:block;width:100%;height:100%}
    .err{color:#e37b7b}
    .info{font-size:12px;color:#888;margin-top:8px}
    label{display:block;margin-top:8px;font-weight:600;font-size:12px}
    button{
      background:#2563eb;color:#fff;border:none;padding:10px 16px;
      border-radius:6px;cursor:pointer;font-weight:600;font-size:13px;
      margin-top:8px;width:100%;transition:background 0.2s
    }
    button:hover{background:#1d4ed8}
    button:active{background:#1e40af}
    
    /* Mobile responsive layout */
    @media (max-width: 768px) {
      .app{
        grid-template-columns:1fr;
        grid-template-rows:50vh auto;
      }
      .sidebar{
        grid-template-rows:auto auto;
        max-height:50vh;
      }
      #camWrap{
        max-height:200px;
      }
      #morphKeys{
        max-height:60px;
        font-size:10px;
      }
    }
    
    @media (max-width: 480px) {
      html,body{font:12px system-ui}
      .app{grid-template-rows:40vh auto}
      #ui{padding:8px}
      button{padding:8px 12px;font-size:12px}
      label{font-size:11px}
      .info{font-size:11px}
    }
  </style>
</head>
<body>
  <div class="app">
    <div class="view">
      <canvas id="three"></canvas>
    </div>

    <div class="sidebar">
      <div id="ui">
        <div><b>mirror face</b></div>
        <button id="demoBtn">load demo avatar</button>
        <label>or load from url</label>
        <input type="text" id="urlInput" placeholder="https://example.com/model.glb" style="width:100%;padding:8px;background:#0f0f0f;border:1px solid #333;color:#ddd;border-radius:6px;font-size:13px" />
        <button id="urlBtn">load from url</button>
        <label>or upload your own model (glb/gltf)</label>
        <input type="file" id="file" accept=".glb,.gltf" />
        <label>detected morph target keys</label>
        <div id="morphKeys"></div>
        <div class="info">using mediapipe's native 52 arkit blendshapes + proper neck/head hierarchy!</div>
        <div id="status">waiting for model…</div>
        <button> <a href="https://github.com/Emmanuel-PaulMaah/mirror-face/tree/main">docs</a></button>
      </div>

      <div id="camWrap">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
      </div>
    </div>
  </div>

  <script type="module">
    import * as THREE from "https://cdn.jsdelivr.net/npm/three@0.160.0/+esm";
    import { GLTFLoader } from "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/loaders/GLTFLoader.js/+esm";
    import { OrbitControls } from "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/controls/OrbitControls.js/+esm";

    const canvas = document.getElementById('three');
    const statusEl = document.getElementById('status');
    const morphKeysEl = document.getElementById('morphKeys');
    const overlay = document.getElementById('overlay');
    const video = document.getElementById('video');

    // Scene
    const renderer = new THREE.WebGLRenderer({ canvas, antialias:true, alpha:true });
    renderer.setPixelRatio(Math.min(devicePixelRatio, 2));
    const scene = new THREE.Scene(); 
    scene.background = new THREE.Color(0x111111);
    const camera = new THREE.PerspectiveCamera(35, 1, 0.01, 100); 
    camera.position.set(0,1.2,2.2);
    const hemi = new THREE.HemisphereLight(0xffffff,0x222233,1.1); scene.add(hemi);
    const dir  = new THREE.DirectionalLight(0xffffff,1.1); dir.position.set(2,3,2); scene.add(dir);
    const grid = new THREE.GridHelper(6,12,0x333333,0x222222); grid.position.y=-1; scene.add(grid);

    const controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.dampingFactor = 0.08;
    controls.minDistance = 0.5;
    controls.maxDistance = 10;
    controls.enablePan = true;
    controls.target.set(0, 1, 0);

    function frameObject(obj) {
      const box = new THREE.Box3().setFromObject(obj);
      const sizeV = box.getSize(new THREE.Vector3());
      const size = Math.max(sizeV.x, sizeV.y, sizeV.z);
      const center = box.getCenter(new THREE.Vector3());
      const fitHeight = size / (2 * Math.tan(THREE.MathUtils.degToRad(camera.fov * 0.5)));
      const fitWidth  = fitHeight / camera.aspect;
      const dist = 1.2 * Math.max(fitHeight, fitWidth);
      camera.near = Math.max(0.01, size / 100);
      camera.far  = Math.max(100, size * 10);
      camera.position.copy(center).add(new THREE.Vector3(0, size * 0.15, dist));
      camera.updateProjectionMatrix();
      controls.target.copy(center);
      controls.update();
    }

    function resize(){
      const view = canvas.parentElement.getBoundingClientRect();
      renderer.setSize(view.width, view.height, false);
      camera.aspect = view.width / view.height;
      camera.updateProjectionMatrix();
      const vr = document.getElementById('video').getBoundingClientRect();
      overlay.width  = Math.max(1, Math.floor(vr.width));
      overlay.height = Math.max(1, Math.floor(vr.height));
    }
    addEventListener('resize', resize);
    new ResizeObserver(resize).observe(document.body);
    resize();

    (function loop(){
      requestAnimationFrame(loop);
      controls.update();
      renderer.render(scene, camera);
    })();

    let morphRefs = [];
    const gltfLoader = new GLTFLoader();

    function collectMorphMeshes(root){
      const out=[]; 
      root.traverse(o=>{
        if(o.isMesh && o.morphTargetDictionary && o.morphTargetInfluences){
          out.push({ dict:o.morphTargetDictionary, inf:o.morphTargetInfluences });
        }
      });
      return out;
    }

    function unionMorphKeys(refs){
      const s=new Set();
      refs.forEach(r=>Object.keys(r.dict).forEach(k=>s.add(k)));
      return Array.from(s).sort();
    }

    // Store original bone rotations (rest pose)
    let neckRestQuat = null, headRestQuat = null;

    // Shared model loading function
    async function loadModel(url, shouldRevoke = true) {
      statusEl.textContent = 'Loading model…';
      try{
        const gltf = await gltfLoader.loadAsync(url);
        gltf.scene.position.set(0,-1,0);
        scene.add(gltf.scene);
        frameObject(gltf.scene);

        morphRefs = collectMorphMeshes(gltf.scene);

        // Find BOTH neck and head bones
        let neckNode = null, headNode = null;
        gltf.scene.traverse(o=>{
          if(o.isBone || o.isObject3D){
            const n = o.name.toLowerCase();
            // Neck detection
            if(!neckNode && (/neck/i.test(o.name) || /spine.*3/i.test(o.name) || /cervical/i.test(o.name))){
              neckNode = o;
            }
            // Head detection
            if(!headNode && (/\bhead\b/i.test(o.name) || /Head_JNT/i.test(o.name) || /DEF-Head/i.test(o.name) || /mixamorigHead/i.test(o.name))){
              headNode = o;
            }
          }
        });

        // Fallback: if no neck found but head found, use head's parent as neck
        if(headNode && !neckNode && headNode.parent && headNode.parent !== gltf.scene){
          neckNode = headNode.parent;
        }

        window.neckNode = neckNode;
        window.headNode = headNode || gltf.scene;
        
        // CRITICAL FIX: Store original rest pose instead of zeroing
        if(neckNode && neckNode.quaternion) {
          neckRestQuat = neckNode.quaternion.clone();
        }
        if(headNode && headNode.quaternion) {
          headRestQuat = headNode.quaternion.clone();
        }

        console.log('Bones found:', { 
          neck: neckNode?.name, 
          head: headNode?.name,
          neckRest: neckRestQuat,
          headRest: headRestQuat
        });

        if(morphRefs.length===0){ 
          statusEl.innerHTML = '<span class="err">No morph targets found.</span>'; 
          return; 
        }

        const keys = unionMorphKeys(morphRefs);
        morphKeysEl.textContent = keys.join(', ');
        statusEl.textContent = 'Model ready. Starting webcam + tracking…';
      }catch(err){ 
        console.error(err); 
        statusEl.innerHTML = '<span class="err">Model load failed.</span>'; 
      }
      finally{ 
        if(shouldRevoke) URL.revokeObjectURL(url); 
      }
    }

    // Demo button handler
    document.getElementById('demoBtn').addEventListener('click', async ()=>{
      await loadModel('demo-avatar.glb', false);
    });

    // URL button handler
    document.getElementById('urlBtn').addEventListener('click', async ()=>{
      const url = document.getElementById('urlInput').value.trim();
      if(!url) {
        statusEl.innerHTML = '<span class="err">Please enter a URL.</span>';
        return;
      }
      await loadModel(url, false);
    });

    // File upload handler
    document.getElementById('file').addEventListener('change', async (e)=>{
      const file = e.target.files?.[0]; if(!file) return;
      const url = URL.createObjectURL(file);
      await loadModel(url, true);
    });

    window.__rigShared__ = {
      get morphRefs(){return morphRefs;},
      get neckRestQuat(){return neckRestQuat;},
      get headRestQuat(){return headRestQuat;}
    };
  </script>

  <!-- MediaPipe FaceLandmarker with native blendshapes -->
  <script type="module">
    import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14";
    
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const statusEl = document.getElementById('status');

    let faceLandmarker;
    let lastVideoTime = -1;

    // Smoothing for blendshapes and rotation
    const ema = alpha => { 
      let val = 0, init = false; 
      return v => { val = init ? (alpha*v + (1-alpha)*val) : (init=true, v); return val; }; 
    };

    const blendshapeFilters = {};
    let rotQuat = {x:0, y:0, z:0, w:1};

    function qNormalize(q){
      const m = Math.hypot(q.x,q.y,q.z,q.w)||1; 
      return {x:q.x/m, y:q.y/m, z:q.z/m, w:q.w/m};
    }

    function qMultiply(a, b) {
      return {
        w: a.w*b.w - a.x*b.x - a.y*b.y - a.z*b.z,
        x: a.w*b.x + a.x*b.w + a.y*b.z - a.z*b.y,
        y: a.w*b.y - a.x*b.z + a.y*b.w + a.z*b.x,
        z: a.w*b.z + a.x*b.y - a.y*b.x + a.z*b.w
      };
    }

    function qSlerp(a, b, t){
      let cos = a.x*b.x + a.y*b.y + a.z*b.z + a.w*b.w;
      if (cos < 0) { b = {x:-b.x, y:-b.y, z:-b.z, w:-b.w}; cos = -cos; }
      if (cos > 0.9995) {
        const x=a.x+(b.x-a.x)*t, y=a.y+(b.y-a.y)*t, z=a.z+(b.z-a.z)*t, w=a.w+(b.w-a.w)*t;
        return qNormalize({x,y,z,w});
      }
      const th = Math.acos(Math.min(1, cos));
      const s = Math.sin(th);
      const w1 = Math.sin((1-t)*th)/s, w2 = Math.sin(t*th)/s;
      return {x:a.x*w1+b.x*w2, y:a.y*w1+b.y*w2, z:a.z*w1+b.z*w2, w:a.w*w1+b.w*w2};
    }

    function matrixToQuaternion(m) {
      // m is 4x4 matrix as Float32Array (column-major)
      const m00=m[0], m01=m[4], m02=m[8];
      const m10=m[1], m11=m[5], m12=m[9];
      const m20=m[2], m21=m[6], m22=m[10];

      let qw, qx, qy, qz;
      const t = m00 + m11 + m22;
      if (t > 0) {
        const s = Math.sqrt(t + 1.0) * 2;
        qw = 0.25 * s;
        qx = (m21 - m12) / s;
        qy = (m02 - m20) / s;
        qz = (m10 - m01) / s;
      } else if (m00 > m11 && m00 > m22) {
        const s = Math.sqrt(1.0 + m00 - m11 - m22) * 2;
        qw = (m21 - m12) / s;
        qx = 0.25 * s;
        qy = (m01 + m10) / s;
        qz = (m02 + m20) / s;
      } else if (m11 > m22) {
        const s = Math.sqrt(1.0 + m11 - m00 - m22) * 2;
        qw = (m02 - m20) / s;
        qx = (m01 + m10) / s;
        qy = 0.25 * s;
        qz = (m12 + m21) / s;
      } else {
        const s = Math.sqrt(1.0 + m22 - m00 - m11) * 2;
        qw = (m10 - m01) / s;
        qx = (m02 + m20) / s;
        qy = (m12 + m21) / s;
        qz = 0.25 * s;
      }
      return qNormalize({x:qx, y:qy, z:qz, w:qw});
    }

    function applyTracking(blendshapes, transformMatrix) {
      const shared = window.__rigShared__;
      if(!shared?.morphRefs) return;

      // Apply head/neck rotation from transformation matrix
      if(transformMatrix && transformMatrix.data) {
        const headQuat = matrixToQuaternion(transformMatrix.data);
        const smoothness = 0.25;
        rotQuat = qSlerp(rotQuat, headQuat, smoothness);

        // Apply to neck (40% of rotation) and head (60% of rotation)
        if(window.neckNode && window.neckNode.quaternion && shared.neckRestQuat) {
          const neckRotation = qSlerp({x:0,y:0,z:0,w:1}, rotQuat, 0.4);
          const finalNeck = qMultiply(shared.neckRestQuat, neckRotation);
          window.neckNode.quaternion.copy(finalNeck);
        }

        if(window.headNode && window.headNode.quaternion && shared.headRestQuat) {
          const headRotation = qSlerp({x:0,y:0,z:0,w:1}, rotQuat, 0.6);
          const finalHead = qMultiply(shared.headRestQuat, headRotation);
          window.headNode.quaternion.copy(finalHead);
        }
      }

      // Apply all 52 native ARKit blendshapes from MediaPipe
      if(!blendshapes) return;

      // Convert blendshapes array to object for easier access
      const blendshapeMap = {};
      blendshapes.forEach(bs => {
        const name = bs.categoryName;
        const value = bs.score;
        
        // Apply smoothing
        if(!blendshapeFilters[name]) blendshapeFilters[name] = ema(0.35);
        blendshapeMap[name] = blendshapeFilters[name](value);
      });

      // Apply to morph targets
      for(const ref of shared.morphRefs){
        const keys = Object.keys(ref.dict);
        
        // Direct ARKit name matching
        for(const [shapeName, value] of Object.entries(blendshapeMap)){
          if(ref.dict[shapeName] !== undefined){
            ref.inf[ref.dict[shapeName]] = Math.max(0, Math.min(1, value));
          }
        }

        // Heuristic fallback for non-standard naming
        for(const key of keys){
          const lk = key.toLowerCase();
          
          // Eyes
          if(/blink.*left|eye.*close.*left|left.*blink/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.eyeBlinkLeft || 0;
          if(/blink.*right|eye.*close.*right|right.*blink/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.eyeBlinkRight || 0;
          if(/eye.*wide.*left|left.*eye.*wide/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.eyeWideLeft || 0;
          if(/eye.*wide.*right|right.*eye.*wide/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.eyeWideRight || 0;
          
          // Jaw
          if(/jaw.*open|mouth.*open/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.jawOpen || 0;
          if(/jaw.*left/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.jawLeft || 0;
          if(/jaw.*right/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.jawRight || 0;
          
          // Smile/Frown
          if(/smile/i.test(key)) 
            ref.inf[ref.dict[key]] = Math.max(blendshapeMap.mouthSmileLeft||0, blendshapeMap.mouthSmileRight||0);
          if(/frown/i.test(key)) 
            ref.inf[ref.dict[key]] = Math.max(blendshapeMap.mouthFrownLeft||0, blendshapeMap.mouthFrownRight||0);
          
          // Eyebrows
          if(/brow.*up.*left|left.*brow.*up/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.browOuterUpLeft || blendshapeMap.browInnerUp || 0;
          if(/brow.*up.*right|right.*brow.*up/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.browOuterUpRight || blendshapeMap.browInnerUp || 0;
          if(/brow.*down.*left|left.*brow.*down/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.browDownLeft || 0;
          if(/brow.*down.*right|right.*brow.*down/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.browDownRight || 0;
          
          // Mouth shapes
          if(/funnel|pucker|kiss/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.mouthFunnel || blendshapeMap.mouthPucker || 0;
          if(/puff|cheek/i.test(key)) 
            ref.inf[ref.dict[key]] = blendshapeMap.cheekPuff || 0;
        }
      }
    }

    function drawLandmarks(lm){
      const w = overlay.width, h = overlay.height;
      if(!w||!h) return;
      ctx.clearRect(0,0,w,h);
      ctx.lineWidth = Math.max(1, w/400);
      ctx.strokeStyle = '#00ff88';
      ctx.fillStyle = '#00ff88';

      // Draw landmark points
      ctx.beginPath();
      for(const p of lm){
        const x = p.x * w, y = p.y * h;
        ctx.moveTo(x+1, y);
        ctx.arc(x, y, Math.max(1, w/350), 0, Math.PI*2);
      }
      ctx.fill();

      // Face contour
      const outline = [10,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,
                       148,176,149,150,136,172,58,132,93,234,127,162,21,54,103,67,109];
      ctx.strokeStyle = '#00ffaa';
      ctx.beginPath();
      outline.forEach((i,ix)=>{
        const p = lm[i], x=p.x*w, y=p.y*h;
        if(ix===0) ctx.moveTo(x,y); else ctx.lineTo(x,y);
      });
      ctx.stroke();
    }

    async function boot(){
      try {
        // Initialize MediaPipe FaceLandmarker
        statusEl.textContent = 'Loading MediaPipe FaceLandmarker...';
        const filesetResolver = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
        );

        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
          baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
            delegate: "GPU"
          },
          outputFaceBlendshapes: true,  // Enable native ARKit blendshapes!
          outputFacialTransformationMatrixes: true,  // Enable transformation matrix for head pose
          runningMode: "VIDEO",
          numFaces: 1,
          minFaceDetectionConfidence: 0.5,
          minFacePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        // Setup webcam
        statusEl.textContent = 'Requesting webcam access...';
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: { facingMode:'user', width:640, height:480 }, 
          audio:false 
        });
        video.srcObject = stream;
        await video.play();

        const syncOverlay = ()=> {
          const vr = video.getBoundingClientRect();
          overlay.width  = Math.max(1, Math.floor(vr.width));
          overlay.height = Math.max(1, Math.floor(vr.height));
        };
        video.addEventListener('loadedmetadata', syncOverlay);
        new ResizeObserver(syncOverlay).observe(document.getElementById('camWrap'));

        // Start detection loop
        function detectFace() {
          const nowInMs = Date.now();
          
          if (video.currentTime !== lastVideoTime) {
            lastVideoTime = video.currentTime;
            
            const results = faceLandmarker.detectForVideo(video, nowInMs);
            
            if(results.faceLandmarks && results.faceLandmarks[0]) {
              drawLandmarks(results.faceLandmarks[0]);
            }

            const blendshapes = results.faceBlendshapes?.[0]?.categories;
            const transformMatrix = results.facialTransformationMatrixes?.[0];
            
            applyTracking(blendshapes, transformMatrix);
          }
          
          requestAnimationFrame(detectFace);
        }

        detectFace();
        statusEl.textContent = '✨ Tracking with native 52 ARKit blendshapes!';
      } catch(err) {
        console.error('Boot error:', err);
        statusEl.innerHTML = `<span class="err">Failed to initialize: ${err.message}</span>`;
      }
    }
    
    if(document.readyState === 'loading') {
      document.addEventListener('DOMContentLoaded', boot);
    } else {
      boot();
    }
  </script>
</body>
</html>
